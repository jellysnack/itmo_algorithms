{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm from the book: longest common subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs(xs, ys): \n",
    "    m, n = len(xs), len(ys) \n",
    "    d = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    b = [[None] * n for _ in range(m)]\n",
    "  \n",
    "    for i in range(1, m + 1): \n",
    "        for j in range(1, n + 1): \n",
    "            if xs[i - 1] == ys[j - 1]: \n",
    "                d[i][j] = d[i - 1][j - 1] + 1\n",
    "                b[i - 1][j - 1] = \"d\"\n",
    "            elif d[i - 1][j] >= d[i][j - 1]:\n",
    "                d[i][j] = d[i - 1][j]\n",
    "                b[i - 1][j - 1] = \"u\"\n",
    "            else:\n",
    "                d[i][j] = d[i][j - 1]\n",
    "                b[i - 1][j - 1] = \"b\"\n",
    "  \n",
    "    return d[m][n], b\n",
    "\n",
    "\n",
    "def print_lcs(b, xs, i, j):\n",
    "    if i == -1 or j == -1:\n",
    "        return\n",
    "    if b[i][j] == \"d\":\n",
    "        print_lcs(b, xs, i - 1, j - 1)\n",
    "        print(xs[i], end=\"\")\n",
    "    elif b[i][j] == \"u\":\n",
    "        print_lcs(b, xs, i - 1, j)\n",
    "    else:\n",
    "        print_lcs(b, xs, i, j - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the LCS is 3\n",
      "LCS: XYZ"
     ]
    }
   ],
   "source": [
    "X = \"XAAYAAAAZA\"\n",
    "Y = \"BBXBYBBBZ\"\n",
    "res = lcs(X, Y)\n",
    "\n",
    "print(\"The length of the LCS is\", res[0])\n",
    "print(\"LCS: \", end=\"\")\n",
    "print_lcs(res[1], X, len(X) - 1, len(Y) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm from research paper:  AdaBelief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.4591910887680559\n",
      "beta = 0.0379706926337019\n"
     ]
    }
   ],
   "source": [
    "# loading data from task 3 to compare results\n",
    "\n",
    "alpha = np.load(\"../task3/data/alpha.npy\")[0]\n",
    "beta = np.load(\"../task3/data/beta.npy\")[0]\n",
    "print(f\"alpha = {alpha}\")\n",
    "print(f\"beta = {beta}\")\n",
    "\n",
    "xs = np.load(\"../task3/data/xs.npy\")[0].tolist()\n",
    "ys = np.load(\"../task3/data/ys.npy\")[0].tolist()\n",
    "n = len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "def rational(x, a, b):\n",
    "    return a / (1 + b * x)\n",
    "\n",
    "grad = {\n",
    "    linear: lambda x, a, b: (x, 1),\n",
    "    rational: lambda x, a, b: (1 / (b * x + 1), a * x / (b * x + 1) ** 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D(x, f, reduce=\"sum\"):    \n",
    "    a, b = x\n",
    "    result = np.array([(f(x, a, b) - y) ** 2 for x, y in zip(xs, ys)])\n",
    "    if reduce == \"sum\":\n",
    "        return result.sum()\n",
    "    elif reduce == \"mean\":\n",
    "        return result.mean()\n",
    "    elif reduce == \"none\":\n",
    "        return result\n",
    "    else:\n",
    "        raise Exception\n",
    "\n",
    "def get_gradient(x, f, reduce=\"mean\"):    \n",
    "    a, b = x\n",
    "    g1 = np.array([2 * grad[f](x, a, b)[0] * (f(x, a, b) - y) for x, y in zip(xs, ys)])\n",
    "    g2 = np.array([2 * grad[f](x, a, b)[1] * (f(x, a, b) - y) for x, y in zip(xs, ys)])\n",
    "    \n",
    "    if reduce == \"sum\":\n",
    "        return np.array([g1.sum(), g2.sum()])\n",
    "    elif reduce == \"mean\":\n",
    "        return np.array([g1.mean(), g2.mean()])\n",
    "    elif reduce == \"none\":\n",
    "        return np.stack([g1, g2]).reshape(n, -1)\n",
    "    else:\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adabelief(f, x0, betas=(0.9, 0.999), lr=0.1, k=0.5, max_iters=100, tol=0.001, eps=1e-8):\n",
    "    a, b = x0\n",
    "    b1, b2 = betas\n",
    "    \n",
    "    a_prev = b_prev = float(\"inf\")\n",
    "    t = 0\n",
    "    m = np.array([0, 0])\n",
    "    s = np.array([0, 0])\n",
    "    loss = []\n",
    "    while t < max_iters and math.sqrt((a - a_prev) ** 2 + (b - b_prev) ** 2) > tol:\n",
    "        t += 1\n",
    "        a_prev, b_prev = a, b\n",
    "        \n",
    "        # calculate gradient\n",
    "        g1, g2 = get_gradient((a, b), f)\n",
    "        g = np.array([g1, g2])\n",
    "        \n",
    "        m = b1 * m + (1 - b1) * g\n",
    "        s = b2 * s + (1 - b2) * (g - m) ** 2\n",
    "    \n",
    "        # update parameters\n",
    "        a -= lr * m[0] / (np.sqrt(s[0]) + eps)\n",
    "        b -= lr * m[1] / (np.sqrt(s[1]) + eps)\n",
    "        \n",
    "        loss.append(D((a, b), f))\n",
    "        \n",
    "        # update learning rate\n",
    "        lr *= 1 / (1 + k * t)  \n",
    "\n",
    "    return (a, b), t, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear approximant:\n",
      "fun: 87.20763531929803\n",
      "nit: 21\n",
      "  x: [0.05632552682610621, 0.33733165259521936]\n"
     ]
    }
   ],
   "source": [
    "result = adabelief(linear, (-0.05, 0.05), lr=0.1, k=0.03)\n",
    "a, b = result[0]\n",
    "\n",
    "print(\"Linear approximant:\")\n",
    "print(f\"fun: {D((a, b), linear)}\")\n",
    "print(f\"nit: {result[1]}\")\n",
    "print(f\"  x: {[a, b]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rational approximant:\n",
      "fun: 87.22589704852011\n",
      "nit: 6\n",
      "  x: [0.350786471789178, -0.05833229794727621]\n"
     ]
    }
   ],
   "source": [
    "result = adabelief(rational, (-0.05, 0.05), lr=0.055, k=0.85)\n",
    "a, b = result[0]\n",
    "\n",
    "print(\"Rational approximant:\")\n",
    "print(f\"fun: {D((a, b), rational)}\")\n",
    "print(f\"nit: {result[1]}\")\n",
    "print(f\"  x: {[a, b]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
